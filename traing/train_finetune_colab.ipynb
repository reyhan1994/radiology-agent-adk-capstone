"""
train_finetune_colab.py

This script allows you to fine-tune the ResNet18 model on the Chest X-ray Pneumonia dataset.
- Downloads dataset from Kaggle
- Sets up Google Drive for saving model weights
- Trains for 3 epochs (can be modified)
- Saves fine-tuned weights to Google Drive
- Runs main.py for inference and generates submission.csv
"""

import os
import torch
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader
import torch.nn as nn
from google.colab import drive
import gdown
import json

# ----------------------------------------
# Check GPU
# ----------------------------------------
print("GPU Available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

# ----------------------------------------
# Clone repository (if not already)
# ----------------------------------------
repo_path = "/content/radiology-agent-adk-capstone"
if not os.path.exists(repo_path):
    !git clone https://github.com/reyhan1994/radiology-agent-adk-capstone.git
os.chdir(repo_path)
print("Repo files:", os.listdir(repo_path))

# ----------------------------------------
# Install dependencies
# ----------------------------------------
!pip install -q torch torchvision kaggle gdown

# Setup Kaggle API (environment variables recommended)
# ----------------------------------------your_username
os.environ["KAGGLE_USERNAME"] = "your_username"
os.environ["KAGGLE_KEY"] = "your_api_key"
kaggle_username = os.environ.get("KAGGLE_USERNAME")
kaggle_key      = os.environ.get("KAGGLE_KEY")
if kaggle_username and kaggle_key:
    os.makedirs("/root/.kaggle", exist_ok=True)
    with open("/root/.kaggle/kaggle.json", "w") as f:
        json.dump({"username": kaggle_username, "key": kaggle_key}, f)
    os.chmod("/root/.kaggle/kaggle.json", 0o600)
    !kaggle -v
else:
    print("⚠️ Kaggle credentials not set. Set KAGGLE_USERNAME and KAGGLE_KEY env variables.")


# Download dataset
# ----------------------------------------
dataset_dir = "/content/pneumonia_dataset"
if not os.path.exists(dataset_dir):
    !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia --unzip -p {dataset_dir}

# Fix folder structure
train_dir = os.path.join(dataset_dir, "chest_xray/train")
test_dir  = os.path.join(dataset_dir, "chest_xray/test")
os.makedirs(train_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)


# Mount Google Drive for storing model weights
# ----------------------------------------
drive.mount('/content/drive')
weights_path = "/content/drive/MyDrive/radiology_agent/models/chest_classifier.pt"
os.makedirs(os.path.dirname(weights_path), exist_ok=True)

# ----------------------------------------
# Download fine-tuned weights if not present
# ----------------------------------------
if not os.path.exists(weights_path):
    gdown.download(
        url="https://drive.google.com/uc?id=1mDpUmGjR5OKXodd8DxFJVsR-iMsrPuIb",
        output=weights_path,
        quiet=False
    )
print("✅ Model weights path:", weights_path)

# Define image transformations
# ----------------------------------------
tf = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.Grayscale(num_output_channels=3),  # Convert 1-channel X-ray to 3-channel
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])  # ImageNet normalization
])

# ----------------------------------------
# Create Dataset and DataLoader
# ----------------------------------------
train_ds = datasets.ImageFolder(train_dir, transform=tf)
test_ds  = datasets.ImageFolder(test_dir, transform=tf)

train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)
test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False)

# ----------------------------------------
# Load pretrained ResNet18 model
# ----------------------------------------
model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, 3)  # Replace final layer for 3 classes: Normal / Pneumonia / Other
model = model.to(device)

# ----------------------------------------
# Define loss function and optimizer
# ----------------------------------------
criterion = nn.CrossEntropyLoss()
opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)

# ----------------------------------------
# Training loop
# ----------------------------------------
epochs = 3
for epoch in range(epochs):
    model.train()
    running_loss = 0
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)

        opt.zero_grad()
        logits = model(xb)
        loss = criterion(logits, yb)
        loss.backward()
        opt.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f}")

# ----------------------------------------
# Save trained model weights to Google Drive
# ----------------------------------------
torch.save(model.state_dict(), weights_path )
print("✅ Fine-tune done. Weights saved to:", weights_path )

# Pull latest GitHub updates and run main.py for Kaggle submission
# ----------------------------------------
!git pull
!PYTHONPATH=. python main.py --input sample_images --output submission.csv


# Download submission CSV locally
# ----------------------------------------
from google.colab import files
files.download("submission.csv")

# Download model weights locally (optional)
# ----------------------------------------
weights_path = save_path
files.download(weights_path)
